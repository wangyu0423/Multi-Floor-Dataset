# Multi-Floor-Dataset
Self-collected, Multi-Floor, Public Datasets

# Introduction

*Y. Wang, G. Zhou, C. Xiang, S. Zhang, S. Xu, X. Ma, Q. X and H. Y. Two-Stage Joint Visual and Wireless Feature based Mechanism for Multi-Floor Indoor Localization, Submitted to IEEE Communications Letters.*

  In order to better introduce the experimental environment of this letter, we open source the dataset. All data in this dataset are collected by ourselves.


# The Scene of Data acquisition
  Our proposed two-stage localization scheme is verified in the corridor environment of a typical office building, which contains four floors with 4000 square meters area for each floor. In this figure, the first line are the layout of a single floor and data acquisition equipment, the following are some examples of image of four floors. In the experimental building with four floors, the 1, 2, 3, floors are used as base floors, the 4 floor is used as novel floor to test.

  As shown in this figure, the layout of each floor is more or less the same with dramatically changing lighting conditions throughout the day. Meanwhile, the WiFi signals are in general unreliable, due to the regular daily activities of working staffs. In the above settings, both the signal feature based localization (SFBL) and the visual based localization (VBL) schemes cannot achieve satisfying localization results, which raises a great challenge for the fusion-based localization schemes. All the experimental results of our work are compared in this challenging scenario.
  
<img src="https://github.com/wangyu0423/Multi-Floor-Dataset/blob/main/Environment.png" width="500" height="600" alt="Environment">

# The Process of Data acquisition

  In order to obtain the ground truth positions and establish the WiFi fingerprint databases and the image database, we have done the following implementation work. Firstly, according to the mobile robot's installation location, the relative position coordinate of camera and IMU module is obtained. Secondly, the real-time coordinates of the mobile robot on the floor are calculated by constructing a two-dimensional floor map through robot SLAM. Thirdly, multiple cruise points are set on map of SLAM, enabling the robot to complete the task while moving autonomously on the floor corridor. Fourthly, the mobile robot take multiple s-shaped trajectory routes to collect data and several slopes are placed in the corridor to increase the position changes on Z-axis. In order to ensure the user localization accuracy, the mobile robot will collect the wireless signal and image data periodically to keep the WiFi fingerprint databases and the image database updated. The data training process is conducted on a localization server with NVIDIA Titan X GPU with Pytorch platform. Kindly note that when the offline training process is completed, the online localization service will be provided by the indoor localization server.
  
  In the WiFi fingerprint acquisition process, the data acquisition equipment (mobile robot) and its own configured WiFi module are used to scan the deployed WiFi APs in the current scene, establish communication with multiple access points (APs), receive the received signal strength indications (RSSIs) values from different APs at the current sampling location, and save the RSSI set and location coordinates to the database according to a certain format, e.g., <img src="http://chart.googleapis.com/chart?cht=tx&chl={\mathbf{DB}}_{W}={(\mathcal{R}(\mathbf{L}_{{RP}}^{i}),\mathbf{L}_{{RP}}^{i},\mathbf{F}_{{RP}}^{i})}" style="border:none;">, where <img src="http://chart.googleapis.com/chart?cht=tx&chl=\mathcal{R}(\mathbf{L}_{{RP}}^{i})" style="border:none;"> denotes the APs measured RSSIs, <img src="http://chart.googleapis.com/chart?cht=tx&chl=\mathbf{L}_{RP}^{i}" style="border:none;"> denotes APs locations, <img src="http://chart.googleapis.com/chart?cht=tx&chl=\mathbf{F}_{RP}^{i}" style="border:none;"> denotes the floor index.
  
  As for the image data acquisition process, the data acquisition equipment (mobile robot) and its own configured camera module are used to take images of the experimental scene, and save the images and its corresponding location coordinates to the database according to a certain format, e.g., <img src="http://chart.googleapis.com/chart?cht=tx&chl={\mathcal{DB}}_{I}={(\mathcal{I}(\mathbf{L}_{I}), \mathbf{L}_{I}, \mathbf{F}_{I})}" style="border:none;">, where <img src="http://chart.googleapis.com/chart?cht=tx&chl=\mathcal{I}(\mathbf{L}_{I})" style="border:none;"> denotes currently captured image, <img src="http://chart.googleapis.com/chart?cht=tx&chl=\mathbf{L}_{I}" style="border:none;"> denotes the imageâ€™s location, <img src="http://chart.googleapis.com/chart?cht=tx&chl=\mathbf{F}_{I}" style="border:none;"> denotes the floor index.  
